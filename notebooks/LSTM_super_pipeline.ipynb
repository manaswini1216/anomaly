{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883e81ab-8dcb-4237-855d-e3b165cec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a59f50c-2fe8-4c3e-b10b-75f43bcc1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = r\"C:\\Users\\Manaswini\\Downloads\\data\"\n",
    "\n",
    "FEATURES = [\n",
    "    \"Accelerometer1RMS\",\n",
    "    \"Accelerometer2RMS\",\n",
    "    \"Current\",\n",
    "    \"Pressure\",\n",
    "    \"Temperature\",\n",
    "    \"Thermocouple\",\n",
    "    \"Voltage\",\n",
    "    \"Volume Flow RateRMS\"\n",
    "]\n",
    "\n",
    "TIME_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04aaab69-6fe2-45f8-948d-6408a5e78a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_supervised(data, labels, seq_len):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(labels[i + seq_len - 1])  \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9092ca98-54b9-4940-b067-78588a289c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9405, 8)\n",
      "(9405,)\n"
     ]
    }
   ],
   "source": [
    "normal_path = os.path.join(BASE_PATH, \"anomaly-free\", \"anomaly-free.csv\")\n",
    "\n",
    "normal_df = pd.read_csv(normal_path, sep=\";\")\n",
    "normal_df['datetime'] = pd.to_datetime(normal_df['datetime'])\n",
    "normal_df.set_index('datetime', inplace=True)\n",
    "\n",
    "normal_df = normal_df[FEATURES]\n",
    "\n",
    "normal_labels = np.zeros(len(normal_df))\n",
    "\n",
    "print(normal_df.shape)\n",
    "print(normal_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4080aabf-0cae-4f57-b583-05aae9ee1ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36496, 8)\n",
      "(36496,)\n"
     ]
    }
   ],
   "source": [
    "fault_dfs = []\n",
    "fault_labels = []\n",
    "\n",
    "fault_folders = {\n",
    "    \"Valve1\": range(16),        \n",
    "    \"Valve2\": range(4),         \n",
    "    \"Other\": range(1, 14)       \n",
    "}\n",
    "\n",
    "for folder, file_range in fault_folders.items():\n",
    "    folder_path = os.path.join(BASE_PATH, folder)\n",
    "    \n",
    "    for i in file_range:\n",
    "        file_path = os.path.join(folder_path, f\"{i}.csv\")\n",
    "        \n",
    "        df = pd.read_csv(file_path, sep=\";\")\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df.set_index('datetime', inplace=True)\n",
    "        df = df[FEATURES]\n",
    "        \n",
    "        fault_dfs.append(df)\n",
    "        fault_labels.append(np.ones(len(df)))  \n",
    "\n",
    "fault_df = pd.concat(fault_dfs, axis=0)\n",
    "fault_labels = np.concatenate(fault_labels)\n",
    "\n",
    "print(fault_df.shape)\n",
    "print(fault_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6412f58-046b-4168-874c-4fb28ba4ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45901, 8)\n",
      "(45901,)\n",
      "9405\n",
      "36496\n"
     ]
    }
   ],
   "source": [
    "X_all = pd.concat([normal_df, fault_df], axis=0)\n",
    "y_all = np.concatenate([normal_labels, fault_labels])\n",
    "\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)\n",
    "\n",
    "print((y_all == 0).sum())\n",
    "print((y_all == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8054a398-0168-43a2-9986-ce0745db16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45851, 50, 8)\n",
      "(45851,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "def create_sequences_supervised(X, y, time_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences_supervised(X_scaled, y_all, TIME_STEPS)\n",
    "\n",
    "print(X_seq.shape)\n",
    "print(y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb78636-74a2-4057-adcb-623bbcc6fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36680, 50, 8) (36680,)\n",
      "(9171, 50, 8) (9171,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_seq,\n",
    "    y_seq,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_seq\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08af2d5e-c2bf-4739-8cac-25a2447fba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7484 29196]\n",
      "[1871 7300]\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff1eaff-3265-4f05-9c87-9e7da95fa06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manaswini\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m18,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,137</span> (121.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,137\u001b[0m (121.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,137</span> (121.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,137\u001b[0m (121.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(TIME_STEPS, X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation=\"sigmoid\")  # binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe51084c-4e8e-460d-9ad8-3eb683cf8509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - accuracy: 0.9636 - loss: 0.0814 - val_accuracy: 0.9846 - val_loss: 0.0332\n",
      "Epoch 2/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9836 - loss: 0.0373 - val_accuracy: 0.9840 - val_loss: 0.0389\n",
      "Epoch 3/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9835 - loss: 0.0346 - val_accuracy: 0.9845 - val_loss: 0.0329\n",
      "Epoch 4/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.9835 - loss: 0.0367 - val_accuracy: 0.9874 - val_loss: 0.0226\n",
      "Epoch 5/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9787 - loss: 0.0519 - val_accuracy: 0.9868 - val_loss: 0.0396\n",
      "Epoch 6/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.9845 - loss: 0.0411 - val_accuracy: 0.9822 - val_loss: 0.0357\n",
      "Epoch 7/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.9867 - loss: 0.0296 - val_accuracy: 0.9867 - val_loss: 0.0259\n",
      "Epoch 8/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9863 - loss: 0.0293 - val_accuracy: 0.9867 - val_loss: 0.0239\n",
      "Epoch 9/30\n",
      "\u001b[1m574/574\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.9862 - loss: 0.0299 - val_accuracy: 0.9840 - val_loss: 0.0322\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        \"supervised_lstm_best.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0023f15a-cbcc-40a0-a72f-771a7eb516aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i+time_steps])\n",
    "        ys.append(y[i+time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d158a96d-4dc9-4993-ba9e-f923465bd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manaswini\\AppData\\Local\\Temp\\ipykernel_25772\\318896036.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valve1 file 0.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 1.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 2.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 3.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 4.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 5.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 6.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 7.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 8.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 9.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 10.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 11.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 12.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 13.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 14.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve1 file 15.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve2 file 0.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve2 file 1.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve2 file 2.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Valve2 file 3.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 1.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 2.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 3.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 4.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 5.csv | Acc: 0.748, Prec: 1.000, Rec: 0.748, F1: 0.856\n",
      "Other file 6.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 7.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 8.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 9.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 10.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 11.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 12.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 13.csv | Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000\n",
      "Other file 14.csv | Acc: 0.999, Prec: 1.000, Rec: 0.999, F1: 0.999\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Folder\", \"File\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "test_folders = {\n",
    "    \"Valve1\": 16,\n",
    "    \"Valve2\": 4,\n",
    "    \"Other\": list(range(1, 15))\n",
    "}\n",
    "\n",
    "for folder, files in test_folders.items():\n",
    "    folder_path = os.path.join(BASE_PATH, folder)\n",
    "    \n",
    "    file_indices = files if isinstance(files, list) else range(files)\n",
    "    \n",
    "    for i in file_indices:\n",
    "        file_path = os.path.join(folder_path, f\"{i}.csv\")\n",
    "        \n",
    "        df = pd.read_csv(file_path, sep=\";\")\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df.set_index('datetime', inplace=True)\n",
    "        \n",
    "        X = scaler.transform(df[FEATURES])\n",
    "        y_true = np.ones(len(X)) \n",
    "\n",
    "        X_seq, y_seq = create_sequences(X, y_true, TIME_STEPS)\n",
    "        \n",
    "        y_pred_prob = model.predict(X_seq, verbose=0).ravel()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        \n",
    "        acc = accuracy_score(y_seq, y_pred)\n",
    "        prec = precision_score(y_seq, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_seq, y_pred)\n",
    "        f1 = f1_score(y_seq, y_pred)\n",
    "        \n",
    "        results_df = pd.concat([\n",
    "            results_df,\n",
    "            pd.DataFrame([{\n",
    "                \"Folder\": folder,\n",
    "                \"File\": f\"{i}.csv\",\n",
    "                \"Accuracy\": acc,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"F1\": f1\n",
    "            }])\n",
    "        ], ignore_index=True)\n",
    "        \n",
    "        print(f\"{folder} file {i}.csv | Acc: {acc:.3f}, Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7fdc2cf-1293-451d-bae2-1fc4f5427b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = r\"C:\\Users\\Manaswini\\Downloads\\anomaly\\result_lstm_s\"\n",
    "results_df.to_csv(os.path.join(SAVE_PATH, \"supervised_test_metrics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afa4bb7-0622-4e01-b908-dc81171c8667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Manaswini\\\\Downloads\\\\anomaly\\\\result_lstm_s\\\\timesteps.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model.save(os.path.join(SAVE_PATH, \"supervised_lstm_model.keras\"))\n",
    "joblib.dump(scaler, os.path.join(SAVE_PATH, \"scaler.pkl\"))\n",
    "\n",
    "joblib.dump(FEATURES, os.path.join(SAVE_PATH, \"features.pkl\"))\n",
    "joblib.dump(TIME_STEPS, os.path.join(SAVE_PATH, \"timesteps.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27599f-c039-4a04-9ea7-af5683990223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
